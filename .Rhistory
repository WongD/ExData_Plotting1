?version
R.version
q()
dest <-"C:/Users/D/Documents/Study/Cleansing_Data/hw1.xlsx"
source<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx "
xl <- download.file(source, dest, method="wb")
xl <- download.file(source, dest, mode="wb")
xl <- read.xlsx(xl, sheetIndex=1, colIndex=7:15, rowIndex=18:23)
library(xlsx)
xl <- read.xlsx(xl, sheetIndex=1, colIndex=7:15, rowIndex=18:23)
xl
download.file(source, dest, mode="wb")
xl <- read.xlsx(dest, sheetIndex=1, colIndex=7:15, rowIndex=18:23)
xl
sum(xl$Zip*xl$Ext,na.rm=T)
library(xml)
library(XML)
fileURL <-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternal=TRUE)
doc <- xmlTreeParse(fileURL, useInternal=TRUE)
fileURL <-"http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileURL, useInternal=TRUE)
dox
doc
rootNode <- xmlRoot(doc)
rootNode
names(rootNode)
xpathSApply(rootNode, "//Zipcode", xmlValue)
rootNode
rootNode[[1]]
xmlSApply(rootNode, xmlValue)
xpathSApply(rootNode, "//ZIPCODE", xmlValue)
xpathSApply(rootNode, "//zipcode", xmlValue)
zips <-xpathSApply(rootNode, "//zipcode", xmlValue)
nrow(zips)
table(zips)
rm(list=ls(')'))
rm(list=ls())
source<-https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv
source<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv""
source<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
source<-"http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
dest <-"C:/Users/D/Documents/Study/Cleansing_Data/hw5.csv"
download.file(source, dest)
fread(dest)
library(data.tables)
library(data.table)
DT<-fread(dest)
View(DT)
DT[,mean(pwgtp15),by=SEX]
library(swirl)
swirl()
swirl()
5+7
x<-5+7
x
y<-x-3
y
z<-c(1.1,9,3.14)
?c
z
c(z, 555, z)
z*2+100
my_sqrt<- sqrt(z-1)
my_sqrt
my_div <- z/my_sqrt
my_div
c(1,2,3,4) + c(0,10)
c(1,2,3,4) + c(0,10,100)
z*2+1000
my_div
swirl()
quit
qui()
quit()
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf<-read.csv(path2csv, stringsasFactors=FALSE)
mydf<-read.csv(path2csv, stringsAsFactors=FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?manip
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran, -(x:Size))
select(cran, -(X:Size))
select(cran, -(X:size))
filter(cran, package=="swirl")
filter(cran, r_version =="3.1.1", country =="US")
?Comparison
filter(cran, r_version >="3.0.2", country =="IN")
filter(cran, r_version <="3.0.2", country =="IN")
filter(cran, country =="IN"| country =="US")
filter(cran, size>100500, r_os=="linux-gnu")
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version, ip_id))
arrange(cran2, country, desc(r_version), ip_id)
cran3<- select(cran2, ip_id, package, size)
cran3<- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb=size_mb /2^10)
mutate(cran3,correct_size = size -1000)
mutate(cran3,correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran, package)
by_package
summarize(cran, mean(size))
summarize(by_package, mean(size))
summarize(by_package, n(), n_distinct(ip_id), n_distinct(country), mean(size))
?N
?n
n(cran)
n()
?n_distinct
source('C:/Users/D/AppData/Local/Temp/RtmpeGa4Xd/summarize1.R')
summarize(by_package, count=n(), unique=n_distinct(ip_id), countries=n_distinct(country), avg_bytes=mean(size))
summarize(by_package, count=n())
source('C:/Users/D/AppData/Local/Temp/RtmpeGa4Xd/summarize1.R')
source('C:/Users/D/AppData/Local/Temp/RtmpeGa4Xd/summarize1.R')
submit()
pack_sum
quantile(pack_sum$count, probs=0.99)
top_counts <-filter(pack_sum, count>679)
top_counts
head(top_counts, 20)
arrange(top_counts, desc(count))
quantile(pack_sum$unique, probs=0.99)
top_unique <- filter(top_counts, unique >465)
top_unique <- filter(pack_sum, unique >465)
top_unique
arrange(top_unique, desc(unique))
submit()
submit()
?chain
submit()
source('C:/Users/D/AppData/Local/Temp/RtmpeGa4Xd/chain1.R')
submit()
source('C:/Users/D/AppData/Local/Temp/RtmpeGa4Xd/chain2.R')
submit()
submit()
submit()
source('C:/Users/D/AppData/Local/Temp/RtmpeGa4Xd/chain2.R')
source('C:/Users/D/AppData/Local/Temp/RtmpeGa4Xd/chain2.R')
submit()
submit
submit()
cran
submit()
?mutate
reset()
submit()
submit
submit()
submit()
rm(list=ls())
getwd()
install.packages("RTools")
install.packages("RTools31")
r.Home
R.Home()
R.Home()
R.home()
install.packages("RTools31")
install.packages('RMySQL',type='source')
R.home()
source("http://bioconductor.org/biocLite.R")
biocLite("rhdf5")
library(rhdf5)
created=h5createFile("example.h5")
created
created = h5createGroup("example.h5", "foo")
created = h5createGroup("example.h5", "foo/foobaa")
created
h5ls("exmaple.h5")
h5ls("example.h5")
A = matrix(1:10, nr=5, nc=2)
a
A
h5write(A, "example.h5", "foo/A")
h5ls("example.h5")
h5write(c(12,13,14), "example.h5", "foo/A", index=list(1:3,1))
h5ls("example.h5")
h5read("example.h5", "foo/A"
)
h5read("example.h5", "foo/A", index=list(1:3,1))
install.packages("RMySQL", type="source")
nstall.packages(“RMySQL”, type = “source”)
install.packages(“RMySQL”, type = “source”)
install.packages("RMySQL", type="source")
install.packages("RMySQL", type="source")
rm(list=ls())
packages()
ucscDb <-dbConnect(MySQL(), user="genome", host ="genome-mysql.cse.ucsc.edu"
)
library(RMySQL)
ucscDb <-dbConnect(MySQL(), user="genome", host ="genome-mysql.cse.ucsc.edu"
)
result <- dbGetQuery(ucscDb, "show databases;");dbDisconnect(ucscdb)
result <- dbGetQuery(ucscDb, "show databases;");dbDisconnect(ucscdb)
result <- dbGetQuery(ucscDb, "show databases;");dbDisconnect(ucscdb)
result <- dbDisconnect(ucscdb)
dbDisconnect(ucscdb)
result <- dbGetQuery(ucscDb, "show databases;");
dbDisconnect(ucscdb)
result
dbDisconnect(ucscDb)
quit()
con = url("http://scholar.google.com/citations?user=HI-I6C00AAAJ&hl=en")
htmlCode = readLines(con)
close(con)
htmlCode
library(xml)
library(XML)
url<- con
html<- htmlTreeParse(url, useInternalNodes=T)
url
con
rm()
ls()
url
con
url<-"http://scholar.google.com/citations?user=HI-I6C00AAAJ&hl=en"
url
html<- htmlTreeParse(url, useInternalNodes=T)
html
xpathSApply(html, "//title", xmlValue)
library(httr"")
library(httr)
rm(list=ls())
url<-"http://scholar.google.com/citations?user=HI-I6C00AAAJ&hl=en"
html = GET(url)
html
content2 = content(html, asText="TRUE")
content2 = content(html, as="Text"")
content2 = content(html, as="Text)
content2 = content(html, as="Text")
content2 = content(html, as="text")
content2
parsedHtml = htmlParse(content2, asText="TRUE")
parsedHtml = htmlParse(content2, asText=TRUE)
xpathSApply(parsedHtml, "//title", xmlValue)
pg1 = GET("http://httpbin.org/basic-auth/user/passwd")
pg1
pg1 = GET("http://httpbin.org/basic-auth/user/passwd"), authenticate("user", "passwd")
pg1 = GET("http://httpbin.org/basic-auth/user/passwd", authenticate("user", "passwd")
)
pg1 = GET("http://httpbin.org/basic-auth/user/passwd", authenticate("user", "passwd"))
pg1
names(pg2)
names(pg1)
dim(pg1)
library(swirl)
swirl()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
res<- gather(students2, sex_class, value, -grade)
res<- gather(students2, sex_class, count, -grade)
res
?seperate
?separate
separate(res, sex_class, c("sex", "class"))
submit()
submit()
students3
submit()
?spread
submit()
extract_numeric("class5")
?mutate
submit()
students3
submit()
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE) %>%
spread(test, grade) %>%
mutate(class = extract_numeric(class))
print
submit()
students4
submit()
submit()
submit()
passed
failed
passed <-mutate(passed, status="passed")
failed<-mutate(failed, status="failed")
rbind_list(passed, failed)
sat
?select
submit()
submit()
?separate
submit()
?groupby
?group_by
submit()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package=lubridate)
this_day <-today()
today()
this_day
year(this_day)
wday(this_day)
wday(this_day, label=TRUE)
this_moment<- now()
this_moment
minute(this_moment)
my_date<-ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy(March 12, 1975)
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("--192012")
ymd("1-9-2012")
ymd("1/9/2012")
ymd("1920/1/2")
dt1
ymd_hms("2014-08-23 17:23:02")
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment <- update(hours =4, minutes =2)
this_moment <- update(this_moment, hours =4, minutes =2)
this_moment
nyc <- now("America/New York")
nyc <- now("America/New York") +2
nyc <- now("America/New York")
nyc
nyc <- now("America/New_York")
nyc
depart <- nyc + days(2)
depart
depart <- update(depart, hours(17), minutes(34))
depart <- update(depart, hours=17, minutes=34)
depart
arrive<- depart + hours(15) + minutes(50)
?with_tz
arrive<- with_tz(arive, "Asia/Hong_Kong")
arrive<- with_tz(arrive, "Asia/Hong_Kong")
arrive
last_time<- mdy("June 17, 2008", tz="Sinagapore")
last_time<- mdy("June 17, 2008", tz="Singapore")
last_time
?new_interval
how_long<- new_interval(last_time, arrive)
as.period(how_long)
stopwatch()
quit()
?text
?hist
?boxplot
?plot
?lines
# Check if data exists in working directory (or sub directories)
# if not download data
# create vector of ALL file paths
file_list<-list.files(getwd(), all.files=TRUE, full.names=TRUE, recursive=TRUE)
# check if "household power consumption.txt" file exists
exists = sum(grepl("household_power_consumption.txt", file_list))
#initialise variable
data_source <- character()
# if file does not exist download to working directory and extract it
if (sum(grepl("household_power_consumption.txt", file_list))!=1) {
# Set source url
SourceUrl = "https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2Fhousehold_power_consumption.zip"
# set destination
dest<- paste(getwd(), "/exdata-data-household_power_consumption.zip", sep="")
#download file
download.file(SourceUrl, dest)
# extract file
unzip(dest)
# set source file location
data_source <- paste (getwd(), "/household_power_consumption.txt", sep="")
}
# set source file location if it wasn't downloaded
if (length(data_source)==0) data_source <- file_list[which(grepl("household_power_consumption.txt", file_list)==1)]
# read data into R using read lines
data <- readLines(data_source)
#create regular expression string to filter data to table
x <-paste("^2/2/2007","^1/2/2007", sep="|")
# read relevant data to table
data<-read.table(text=data[grep(x, data)],sep=";",header=FALSE,comment.char="", colClasses = c("character", "character", "numeric","numeric","numeric","numeric","numeric", "numeric", "numeric"))
# add column names
colnames(data)<- c("Date","Time","Global_active_power","Global_reactive_power","Voltage","Global_intensity","Sub_metering_1","Sub_metering_2","Sub_metering_3")
# convert date and time
data$Date <- as.Date(data$Date,"%d/%m/%Y")
###need to figure out how to use strptime with Date AND Time columns
###to create datetime required
View(data)
strptime(data$Time[1], "%H:%M")
strptime(data$Time[1], "%R")
strptime(data$Time[1000], "%R")
strptime(data$Time[1000], "%R", format="$H:%M")
strptime(data$Time[1000], format="$H:%M")
strptime(data$Time[1000], format="%H:%M")
test<- as.Date(C(data$Date, " ", Data$Time), "%Y-%m-%d %H:%M")
test<- as.Date(C(data$Date, " ", Data$Time), "%Y-%m-%d %H:%M:%S")
est<- c(data$Date, " ", Data$Time)
est<- c(data$Date, " ", data$Time)
est
rm(est)
test<- as.Date(c(data$Date, " ", data$Time), "%Y-%m-%d %H:%M:%S")
test
test<- as.Date(c(data$Date[1000], " ", data$Time[1000]), "%Y-%m-%d %H:%M:%S")
test
test<-c(data$Date, " ", data$Time)
test
test<-c(data$Date[1000], " ", data$Time[1000])
test
str(data)
strptime(data$Time[1000])
strptime(data$Time[1000], "$H:%M")
strptime(data$Time[1000], "%H:%M")
c
c(data$date, " ",strptime(data$Time[1000], "%H:%M"))
as.POSIXct(paste(data$Date, data$Time), format="%Y-%m-%d %H:%M:%S")
as.POSIXct(paste(data$Date[1000], data$Time[1000]), format="%Y-%m-%d %H:%M:%S")
data$DateTime = as.POSIXct(paste(data$Date, data$Time), format="%Y-%m-%d %H:%M:%S")
View(data)
hist(data$Global_Active_power)
str(data)
hist(data$Global_active_power)
windows()
hist(data$Global_active_power)
?par
title="Global Active Power"
rm(title)
main="Global Active Power"
hist(data$Global_active_power, main =""Global Active Power"")
hist(data$Global_active_power, main ="Global Active Power)
hist(data$Global_active_power, main ="Global Active Power")
hist(data$Global_active_power)
title(main="Global Active Power", xlab="Global ACtive Power (kilowatts)")
with(data, hist(Global_active_power))
title(main="Global Active Power", xlab="Global ACtive Power (kilowatts)")
hist(data$Global_active_power, type="n")
title(main="Global Active Power", xlab="Global ACtive Power (kilowatts)")
hist(data$Global_active_power, main="Global Active Power", xlab="Global ACtive Power (kilowatts)")
hist(data$Global_active_power, main="Global Active Power", xlab="Global Active Power (kilowatts)")
par("col")
?par
?col
?par(col)
hist(data$Global_active_power, main="Global Active Power", xlab="Global Active Power (kilowatts)", col="red")
windows()
hist(data$Global_active_power, main="Global Active Power", xlab="Global Active Power (kilowatts)", col="red")
setwd("~/Study/Exploratory_Analysis/Assignment1")
png(file="plot1")
hist(data$Global_active_power, main="Global Active Power", xlab="Global Active Power (kilowatts)", col="red")
dev.off()
png(file="plot1.png")
hist(data$Global_active_power, main="Global Active Power", xlab="Global Active Power (kilowatts)", col="red")
dev.off()
dev.off()
dev.off()
rm(list=ls())
# Check if data exists in working directory (or sub directories)
# if not download data
# create vector of ALL file paths
file_list<-list.files(getwd(), all.files=TRUE, full.names=TRUE, recursive=TRUE)
# check if "household power consumption.txt" file exists
exists = sum(grepl("household_power_consumption.txt", file_list))
#initialise variable
data_source <- character()
# if file does not exist download to working directory and extract it
if (sum(grepl("household_power_consumption.txt", file_list))!=1) {
# Set source url
SourceUrl = "https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2Fhousehold_power_consumption.zip"
# set destination
dest<- paste(getwd(), "/exdata-data-household_power_consumption.zip", sep="")
#download file
download.file(SourceUrl, dest)
# extract file
unzip(dest)
# set source file location
data_source <- paste (getwd(), "/household_power_consumption.txt", sep="")
}
rm(list=ls())
